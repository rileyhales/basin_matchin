import math
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tslearn.clustering import TimeSeriesKMeans
from tslearn.preprocessing import TimeSeriesScalerMeanVariance

"""
Adaptation of demo script by: Romain Tavenard
License: BSD 3 clause
https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kmeans.html#sphx-glr-auto-examples-clustering-plot-kmeans-py

explanation of some important variables

time_series:
a numpy array where each row is a time series for a single point and there is 1 row for each series

assigned_clusters:
is the same as km.labels_ and shows the cluster number that each row was assigned. Thus it is a list of the same length 
you provided number of input features/rows

km:
is the kmeans model itself. the valuable information stored in it is the location of the centroid for each cluster. 
the centroids are generated by the 'fit' option and used to 'predict' new matches. they are modified on the fly and 
used in prediction when you call 'fit_predict'

if all we were interested in were the locations of the centroids then we would shuffle the data before putting it into
the clustering algorithm but we need the data to not be shuffled so that we can pair the info against the ordered comids
and know which comid was put into each cluster

n_clusters = km.n_clusters

"""


def fit_kmeans_clusters(series: np.array, name: str, n_clusters: int = 12):
    km = TimeSeriesKMeans(n_clusters=n_clusters, verbose=True, random_state=0)
    assigned_clusters = km.fit_predict(series)
    km.to_pickle(f'data_2_cluster_simulations/{name}_eucl_kmeans_{n_clusters}cluster_model.pickle')

    sz = series.shape[1]
    fig = plt.figure(figsize=(30, 15), dpi=450)
    for yi in range(n_clusters):
        plt.subplot(2, math.ceil(n_clusters / 2), yi + 1)
        for xx in series[assigned_clusters == yi]:
            plt.plot(xx.ravel(), "k-", alpha=.2)
        plt.plot(km.cluster_centers_[yi].ravel(), "r-")
        plt.xlim(0, sz)
        plt.ylim(-3, 3)
        plt.text(0.55, 0.85, 'Cluster %d' % (yi + 1), transform=plt.gca().transAxes)
        if yi == math.floor(n_clusters / 4):
            plt.title("Euclidean $k$-means")

    plt.tight_layout()
    fig.savefig(f'data_2_cluster_simulations/{name}_eucl_kmeans_{n_clusters}cluster.png')
    return


clusters = 12

print('starting fdc')
# fit the simulated fdc groups
time_series = pd.read_csv('data_1_historical_csv/simulated_fdc_normalized.csv', index_col=0).dropna(axis=1)
time_series = np.transpose(time_series.values)
time_series = TimeSeriesScalerMeanVariance().fit_transform(time_series)
fit_kmeans_clusters(time_series, 'fdc', clusters)

print('starting monavg')
# fit the simulated monthly average groups
time_series = pd.read_csv('data_1_historical_csv/simulated_monavg_normalized.csv', index_col=0).dropna(axis=1)
time_series = np.transpose(time_series.values)
time_series = TimeSeriesScalerMeanVariance().fit_transform(time_series)
fit_kmeans_clusters(time_series, 'monavg', clusters)
